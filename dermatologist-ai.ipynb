{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test data directories\n",
    "data_dir = 'data/'\n",
    "train_dir = os.path.join(data_dir, 'train/')\n",
    "valid_dir = os.path.join(data_dir, 'valid/')\n",
    "test_dir = os.path.join(data_dir, 'test/')\n",
    "\n",
    "# classes are folders in each directory with these names\n",
    "classes = ['melanoma', 'nevus', 'seborrheic_keratosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images:  2000\n",
      "Num valid images:  150\n",
      "Num test images:  600\n"
     ]
    }
   ],
   "source": [
    "#Data Augmentation\n",
    "\n",
    "# resnet152 Takes 224x224 images as input, so we resize all of them\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485 , 0.456 ,0.406),(0.229 , 0.224 , 0.225))]) #This normalization from ImageNET\n",
    "\n",
    "valid_transform = transforms.Compose([transforms.RandomResizedCrop(224), \n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.485 , 0.456 ,0.406),(0.229 , 0.224 , 0.225))])\n",
    "test_transform = transforms.Compose([transforms.RandomResizedCrop(224), \n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.485 , 0.456 ,0.406),(0.229 , 0.224 , 0.225))])\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "# print out some data stats\n",
    "print('Num training images: ', len(train_data))\n",
    "print('Num valid images: ', len(valid_data))\n",
    "print('Num test images: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader parameters\n",
    "batch_size = 20\n",
    "num_workers=0\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some sample data\n",
    "\n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(6):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=100352, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        #convolutional layer (224x224x3)\n",
    "        self.conv1 = nn.Conv2d(3 , 64 ,3 ,padding = 1)\n",
    "        #convolutional layer (112x112x64)\n",
    "        self.conv2 = nn.Conv2d(64,128,3,padding=1)\n",
    "        #convolutional layer (56x56x128)\n",
    "        self.conv3 = nn.Conv2d(128,256,3,padding=1)\n",
    "        #convolutional layer (28x28x256)\n",
    "        self.conv4 = nn.Conv2d(256,512,3,padding=1)\n",
    "        #max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        #linear layer (512 * 14 * 14 ->1024)\n",
    "        self.fc1 = nn.Linear(512 *14 * 14 ,1024)\n",
    "        #linear layer (1024 - > 133)\n",
    "        self.fc2 = nn.Linear(1024,3)\n",
    "        #drop out\n",
    "        self.dropout = nn.Dropout(0.20)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        \n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model_scratch.cuda()\n",
    "    \n",
    "print(model_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: select loss function\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer_scratch = optim.Adam(model_scratch.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 17.645259 \tValidation Loss: 1.093355\n",
      "Validation loss decreased (inf --> 1.093355).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.838323 \tValidation Loss: 1.165322\n",
      "Epoch: 3 \tTraining Loss: 0.842822 \tValidation Loss: 1.091962\n",
      "Validation loss decreased (1.093355 --> 1.091962).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.838095 \tValidation Loss: 1.114322\n",
      "Epoch: 5 \tTraining Loss: 0.840147 \tValidation Loss: 1.121272\n",
      "Epoch: 6 \tTraining Loss: 0.840169 \tValidation Loss: 1.071573\n",
      "Validation loss decreased (1.091962 --> 1.071573).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.840234 \tValidation Loss: 1.138545\n",
      "Epoch: 8 \tTraining Loss: 0.843223 \tValidation Loss: 1.167688\n",
      "Epoch: 9 \tTraining Loss: 0.839419 \tValidation Loss: 1.079779\n",
      "Epoch: 10 \tTraining Loss: 0.838522 \tValidation Loss: 1.059720\n",
      "Validation loss decreased (1.071573 --> 1.059720).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.840681 \tValidation Loss: 1.113417\n",
      "Epoch: 12 \tTraining Loss: 0.837321 \tValidation Loss: 1.110888\n",
      "Epoch: 13 \tTraining Loss: 0.835138 \tValidation Loss: 1.140481\n",
      "Epoch: 14 \tTraining Loss: 0.835863 \tValidation Loss: 1.086374\n",
      "Epoch: 15 \tTraining Loss: 0.837855 \tValidation Loss: 1.111088\n",
      "Epoch: 16 \tTraining Loss: 0.836724 \tValidation Loss: 1.118436\n",
      "Epoch: 17 \tTraining Loss: 0.836203 \tValidation Loss: 1.087603\n",
      "Epoch: 18 \tTraining Loss: 0.835839 \tValidation Loss: 1.098774\n",
      "Epoch: 19 \tTraining Loss: 0.836348 \tValidation Loss: 1.104503\n",
      "Epoch: 20 \tTraining Loss: 0.835483 \tValidation Loss: 1.127003\n",
      "Epoch: 21 \tTraining Loss: 0.835544 \tValidation Loss: 1.120938\n",
      "Epoch: 22 \tTraining Loss: 0.835461 \tValidation Loss: 1.111706\n",
      "Epoch: 23 \tTraining Loss: 0.835198 \tValidation Loss: 1.113218\n",
      "Epoch: 24 \tTraining Loss: 0.835645 \tValidation Loss: 1.112467\n",
      "Epoch: 25 \tTraining Loss: 0.835429 \tValidation Loss: 1.115226\n",
      "Epoch: 26 \tTraining Loss: 0.835195 \tValidation Loss: 1.094557\n",
      "Epoch: 27 \tTraining Loss: 0.836306 \tValidation Loss: 1.110276\n",
      "Epoch: 28 \tTraining Loss: 0.835852 \tValidation Loss: 1.106615\n",
      "Epoch: 29 \tTraining Loss: 0.835440 \tValidation Loss: 1.108940\n",
      "Epoch: 30 \tTraining Loss: 0.835480 \tValidation Loss: 1.098066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the following import is required for training to be robust to truncated images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, train_on_gpu, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # move to GPU\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            #first we clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            #forward pass : pass input to model to get output\n",
    "            output = model(data)\n",
    "            #calculating batch loss\n",
    "            loss = criterion(output,target)\n",
    "            #backward pass : loss of gradient computation\n",
    "            loss.backward()\n",
    "            #update parameters by aingle step optimization\n",
    "            optimizer.step()\n",
    "            #train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "            # move to GPU\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            \n",
    "            #forward pass : pass input to model to get output\n",
    "            output = model(data)\n",
    "            #calculating batch loss\n",
    "            loss = criterion(output,target)\n",
    "            #train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "        ## update the average validation loss\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss  <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), 'model_scratch.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "loaders_scratch = {'train' : train_loader,\n",
    "                  'valid' : valid_loader,\n",
    "                  'test' : test_loader\n",
    "                    }\n",
    "\n",
    "# train the model\n",
    "model_scratch = train(30, loaders_scratch, model_scratch, optimizer_scratch, \n",
    "                      criterion_scratch, train_on_gpu, 'model_scratch.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.882768\n",
      "\n",
      "\n",
      "Test Accuracy: 65% (393/600)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, train_on_gpu):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        # move to GPU\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# call test function    \n",
    "test(loaders_scratch, model_scratch, criterion_scratch, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning using ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /home/nobot/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe8632c32494a6f99bde8e81210ee40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define ResNet152 model\n",
    "ResNet152 = models.resnet152(pretrained=True)\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    ResNet152 = ResNet152.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (23): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (24): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (25): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (26): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (27): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (28): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (29): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (30): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (31): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (32): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (33): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (34): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (35): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#loading the ResNet152 pretrained model from pytorch\n",
    "model_transfer_1= ResNet152 \n",
    "print(model_transfer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_transfer_1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "n_inputs =model_transfer_1.fc.in_features\n",
    "last_layer = nn.Linear(n_inputs,3)\n",
    "model_transfer_1.fc = last_layer\n",
    "\n",
    "if train_on_gpu:\n",
    "    model_transfer_1 = model_transfer_1.cuda()\n",
    "    \n",
    "print (model_transfer_1.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = model_transfer_1.parameters()\n",
    "print(\"Params to learn:\")\n",
    "\n",
    "params_to_update = []\n",
    "for name,param in model_transfer_1.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)\n",
    "\n",
    "criterion_transfer_1 = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_transfer_1 = optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following import is required for training to be robust to truncated images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, train_on_gpu, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # move to GPU\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            #first we clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            #forward pass : pass input to model to get output\n",
    "            output = model(data)\n",
    "            #calculating batch loss\n",
    "            loss = criterion(output,target)\n",
    "            #backward pass : loss of gradient computation\n",
    "            loss.backward()\n",
    "            #update parameters by aingle step optimization\n",
    "            optimizer.step()\n",
    "            #train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "            # move to GPU\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            \n",
    "            #forward pass : pass input to model to get output\n",
    "            output = model(data)\n",
    "            #calculating batch loss\n",
    "            loss = criterion(output,target)\n",
    "            #train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "        ## update the average validation loss\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss  <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), 'model_transfer_1.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "loaders_transfer = {'train' : train_loader,\n",
    "                  'valid' : valid_loader,\n",
    "                  'test' : test_loader\n",
    "                    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.800381 \tValidation Loss: 1.183904\n",
      "Validation loss decreased (inf --> 1.183904).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.757300 \tValidation Loss: 0.974199\n",
      "Validation loss decreased (1.183904 --> 0.974199).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.753864 \tValidation Loss: 0.816629\n",
      "Validation loss decreased (0.974199 --> 0.816629).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.690772 \tValidation Loss: 0.788539\n",
      "Validation loss decreased (0.816629 --> 0.788539).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.733234 \tValidation Loss: 1.010782\n",
      "Epoch: 6 \tTraining Loss: 0.682514 \tValidation Loss: 0.792260\n",
      "Epoch: 7 \tTraining Loss: 0.741828 \tValidation Loss: 0.738541\n",
      "Validation loss decreased (0.788539 --> 0.738541).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.694696 \tValidation Loss: 0.999353\n",
      "Epoch: 9 \tTraining Loss: 0.686612 \tValidation Loss: 0.898366\n",
      "Epoch: 10 \tTraining Loss: 0.688252 \tValidation Loss: 1.025356\n",
      "Epoch: 11 \tTraining Loss: 0.710756 \tValidation Loss: 0.816707\n",
      "Epoch: 12 \tTraining Loss: 0.669704 \tValidation Loss: 0.830463\n",
      "Epoch: 13 \tTraining Loss: 0.693698 \tValidation Loss: 0.819839\n",
      "Epoch: 14 \tTraining Loss: 0.683413 \tValidation Loss: 0.775767\n",
      "Epoch: 15 \tTraining Loss: 0.687463 \tValidation Loss: 0.788139\n",
      "Epoch: 16 \tTraining Loss: 0.693121 \tValidation Loss: 0.786517\n",
      "Epoch: 17 \tTraining Loss: 0.682689 \tValidation Loss: 0.842676\n",
      "Epoch: 18 \tTraining Loss: 0.692358 \tValidation Loss: 1.057790\n",
      "Epoch: 19 \tTraining Loss: 0.683866 \tValidation Loss: 0.709437\n",
      "Validation loss decreased (0.738541 --> 0.709437).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.654217 \tValidation Loss: 0.753734\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_transfer_1 =train(20, loaders_transfer, model_transfer_1, optimizer_transfer_1, criterion_transfer_1, train_on_gpu, 'model_transfer_1.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "model_transfer_1.load_state_dict(torch.load('model_transfer_1.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.717117\n",
      "\n",
      "\n",
      "Test Accuracy: 70% (425/600)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, train_on_gpu):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        # move to GPU\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "    \n",
    "# call test function \n",
    "test(loaders_transfer, model_transfer_1, criterion_transfer_1, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transfer learning using Inception_V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images:  2000\n",
      "Num valid images:  150\n",
      "Num test images:  600\n"
     ]
    }
   ],
   "source": [
    "# inception_V3 Takes 299x299 images as input, so we resize all of them\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(299),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.RandomRotation(0, 359),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485 , 0.456 ,0.406),(0.229 , 0.224 , 0.225))]) #This normalization from ImageNET\n",
    "\n",
    "valid_transform = transforms.Compose([transforms.RandomResizedCrop(299), \n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.485 , 0.456 ,0.406),(0.229 , 0.224 , 0.225))])\n",
    "test_transform = transforms.Compose([transforms.RandomResizedCrop(299), \n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.485 , 0.456 ,0.406),(0.229 , 0.224 , 0.225))])\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "# print out some data stats\n",
    "print('Num training images: ', len(train_data))\n",
    "print('Num valid images: ', len(valid_data))\n",
    "print('Num test images: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader parameters\n",
    "batch_size = 20\n",
    "num_workers=0\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /home/nobot/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c191cba44bb849d19f44de263f08c098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# define inception_v3 model\n",
    "inception_v3 = models.inception_v3(pretrained=True)\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    inception_v3 = inception_v3.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_transfer_2= inception_v3\n",
    "print(model_transfer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_transfer_2.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "2048\n",
      "Linear(in_features=768, out_features=3, bias=True)\n",
      "Linear(in_features=2048, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle the auxilary net\n",
    "n_inputs_auxilary =model_transfer_2.AuxLogits.fc.in_features\n",
    "fine_tuned_layer_1 = nn.Linear(n_inputs_auxilary,3)\n",
    "model_transfer_2.AuxLogits.fc = fine_tuned_layer_1 \n",
    "\n",
    "# Handle the primary net\n",
    "n_inputs_primary =model_transfer_2.fc.in_features\n",
    "fine_tuned_layer_2 = nn.Linear(n_inputs_primary,3)\n",
    "model_transfer_2.fc = fine_tuned_layer_2\n",
    "\n",
    "if train_on_gpu:\n",
    "    model_transfer_2 = model_transfer_2.cuda()\n",
    "    \n",
    "    \n",
    "\n",
    "print(n_inputs_auxilary)\n",
    "print(n_inputs_primary)\n",
    "print (model_transfer_2.AuxLogits.fc)\n",
    "print (model_transfer_2.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t AuxLogits.fc.weight\n",
      "\t AuxLogits.fc.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = model_transfer_2.parameters()\n",
    "print(\"Params to learn:\")\n",
    "\n",
    "params_to_update = []\n",
    "for name,param in model_transfer_2.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)\n",
    "\n",
    "criterion_transfer_2 = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_transfer_2 = optim.RMSprop(params_to_update,lr = 0.0001,eps=0.1,weight_decay=0.5,momentum=0.9)\n",
    "# scheduler_transfer_2 = optim.lr_scheduler.StepLR(optimizer_transfer_2, step_size=3, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following import is required for training to be robust to truncated images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, train_on_gpu, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "#         scheduler_transfer_2.step()\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # move to GPU\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            #first we clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            #forward pass : pass input to model to get output\n",
    "            output, aux_outputs = model(data)\n",
    "            #calculating batch loss\n",
    "            loss1 = criterion(output,target)\n",
    "            loss2 = criterion(aux_outputs, target)\n",
    "            loss = loss1 + 0.4*loss2\n",
    "            #backward pass : loss of gradient computation\n",
    "            loss.backward()\n",
    "            #update parameters by aingle step optimization\n",
    "            optimizer.step()\n",
    "            #train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "            # move to GPU\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            \n",
    "            #forward pass : pass input to model to get output\n",
    "            output = model(data)\n",
    "            #calculating batch loss\n",
    "            loss = criterion(output,target)\n",
    "            #train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "        ## update the average validation loss\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss  <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), 'model_transfer_2.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "loaders_transfer = {'train' : train_loader,\n",
    "                  'valid' : valid_loader,\n",
    "                  'test' : test_loader\n",
    "                    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.556762 \tValidation Loss: 1.621543\n",
      "Validation loss decreased (inf --> 1.621543).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 2.029410 \tValidation Loss: 1.376855\n",
      "Validation loss decreased (1.621543 --> 1.376855).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 1.793002 \tValidation Loss: 1.137433\n",
      "Validation loss decreased (1.376855 --> 1.137433).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 1.547155 \tValidation Loss: 1.128858\n",
      "Validation loss decreased (1.137433 --> 1.128858).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 1.387760 \tValidation Loss: 1.103453\n",
      "Validation loss decreased (1.128858 --> 1.103453).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 1.200794 \tValidation Loss: 0.989224\n",
      "Validation loss decreased (1.103453 --> 0.989224).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.131919 \tValidation Loss: 0.885379\n",
      "Validation loss decreased (0.989224 --> 0.885379).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.078311 \tValidation Loss: 1.000301\n",
      "Epoch: 9 \tTraining Loss: 1.049051 \tValidation Loss: 0.934743\n",
      "Epoch: 10 \tTraining Loss: 1.025113 \tValidation Loss: 0.891050\n",
      "Epoch: 11 \tTraining Loss: 1.036746 \tValidation Loss: 0.945229\n",
      "Epoch: 12 \tTraining Loss: 1.041755 \tValidation Loss: 0.958054\n",
      "Epoch: 13 \tTraining Loss: 1.043247 \tValidation Loss: 0.907456\n",
      "Epoch: 14 \tTraining Loss: 1.041406 \tValidation Loss: 0.949320\n",
      "Epoch: 15 \tTraining Loss: 1.049560 \tValidation Loss: 1.017513\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_transfer_2 =train(15, loaders_transfer, model_transfer_2, optimizer_transfer_2, criterion_transfer_2, train_on_gpu, 'model_transfer_2.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "model_transfer_2.load_state_dict(torch.load('model_transfer_2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.755916\n",
      "\n",
      "\n",
      "Test Accuracy: 69% (417/600)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, train_on_gpu):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        # move to GPU\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        #calculating batch loss\n",
    "        loss = criterion(output,target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "    \n",
    "# call test function \n",
    "test(loaders_transfer, model_transfer_2, criterion_transfer_2, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to train after balancing the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of my mistakes in the up code which i have realized now is that i have imbalanced data.\n",
    "I will use this class **imbalanced dataset sampler** implemented by Ufoym team to balance the data.\n",
    "https://github.com/ufoym/imbalanced-dataset-sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of melanoma samples = 521\n",
      "total number of nevus samples = 1843\n",
      "total number of seborrheic_keratosis samples = 386\n"
     ]
    }
   ],
   "source": [
    "# this function is used to check the imbalanced data in our dataset\n",
    "def parse_folder(folder_to_parse):\n",
    "    melanoma_count = 0\n",
    "    nevus_count = 0\n",
    "    seborrheic_keratosis_count = 0\n",
    "\n",
    "    folders_path = Path(folder_to_parse)\n",
    "    for directory in folders_path.iterdir():\n",
    "        if directory.is_dir():\n",
    "            for deep_directory in directory.iterdir():\n",
    "                if deep_directory.is_dir():\n",
    "                    for file in deep_directory.iterdir():\n",
    "                        if file.is_file() and deep_directory.name == 'melanoma':\n",
    "                            melanoma_count +=1\n",
    "                        if file.is_file() and deep_directory.name == 'nevus':\n",
    "                            nevus_count += 1\n",
    "                        if file.is_file() and deep_directory.name == 'seborrheic_keratosis':\n",
    "                            seborrheic_keratosis_count += 1\n",
    "\n",
    "    print('total number of melanoma samples = ' + str(melanoma_count))\n",
    "    print('total number of nevus samples = ' + str(nevus_count))\n",
    "    print('total number of seborrheic_keratosis samples = ' + str(seborrheic_keratosis_count))\n",
    "\n",
    "parse_folder(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see nevus images has more samples than melanoma and seborrheic_keratosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class(imbalanced dataset sampler) implemented by Ufoym team\n",
    "# https://github.com/ufoym/imbalanced-dataset-sampler\n",
    "\n",
    "\n",
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "        callback_get_label func: a callback-like function which takes two arguments - dataset and index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n",
    "\n",
    "        # if indices is not provided,\n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "\n",
    "        # define custom callback\n",
    "        self.callback_get_label = callback_get_label\n",
    "\n",
    "        # if num_samples is not provided,\n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "\n",
    "        # distribution of classes in the dataset\n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "\n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        if self.callback_get_label:\n",
    "            return self.callback_get_label(dataset, idx)\n",
    "        elif isinstance(dataset, torchvision.datasets.MNIST):\n",
    "            return dataset.train_labels[idx].item()\n",
    "        elif isinstance(dataset, torchvision.datasets.ImageFolder):\n",
    "            return dataset.imgs[idx][1]\n",
    "        elif isinstance(dataset, torch.utils.data.Subset):\n",
    "            return dataset.dataset.imgs[idx][1]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation\n",
    "\n",
    "# resnet152 Takes 224x224 images as input, so we resize all of them\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485 , 0.456 ,0.406),(0.229 , 0.224 , 0.225))]) #This normalization from ImageNET\n",
    "\n",
    "valid_transform = transforms.Compose([transforms.CenterCrop(224), \n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.485 , 0.456 ,0.406),(0.229 , 0.224 , 0.225))])\n",
    "test_transform = transforms.Compose([transforms.CenterCrop(224), \n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.485 , 0.456 ,0.406),(0.229 , 0.224 , 0.225))])\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "\n",
    "# define dataloader parameters\n",
    "batch_size = 20\n",
    "num_workers=0\n",
    "\n",
    "# prepare data loaders\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,sampler=ImbalancedDatasetSampler(train_data),\n",
    "                                          num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,sampler=ImbalancedDatasetSampler(valid_data),\n",
    "                                          num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,sampler=ImbalancedDatasetSampler(test_data),\n",
    "                                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning using ResNet152 with balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ResNet152 model\n",
    "ResNet152 = models.resnet152(pretrained=True)\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    ResNet152 = ResNet152.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (23): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (24): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (25): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (26): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (27): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (28): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (29): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (30): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (31): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (32): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (33): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (34): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (35): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#loading the ResNet152 pretrained model from pytorch\n",
    "model_transfer_3= ResNet152 \n",
    "print(model_transfer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_transfer_3.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "n_inputs =model_transfer_3.fc.in_features\n",
    "last_layer = nn.Linear(n_inputs,3)\n",
    "model_transfer_3.fc = last_layer\n",
    "\n",
    "if train_on_gpu:\n",
    "    model_transfer_3 = model_transfer_3.cuda()\n",
    "    \n",
    "print (model_transfer_3.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = model_transfer_3.parameters()\n",
    "print(\"Params to learn:\")\n",
    "\n",
    "params_to_update = []\n",
    "for name,param in model_transfer_3.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)\n",
    "\n",
    "criterion_transfer_3 = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_transfer_3 = optim.Adam(params_to_update, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following import is required for training to be robust to truncated images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, train_on_gpu, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # move to GPU\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            #first we clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            #forward pass : pass input to model to get output\n",
    "            output = model(data)\n",
    "            #calculating batch loss\n",
    "            loss = criterion(output,target)\n",
    "            #backward pass : loss of gradient computation\n",
    "            loss.backward()\n",
    "            #update parameters by aingle step optimization\n",
    "            optimizer.step()\n",
    "            #train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "            # move to GPU\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            \n",
    "            #forward pass : pass input to model to get output\n",
    "            output = model(data)\n",
    "            #calculating batch loss\n",
    "            loss = criterion(output,target)\n",
    "            #train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "        ## update the average validation loss\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss  <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), 'model_transfer_3.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "loaders_transfer = {'train' : train_loader,\n",
    "                  'valid' : valid_loader,\n",
    "                  'test' : test_loader\n",
    "                    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.001754 \tValidation Loss: 0.762207\n",
      "Validation loss decreased (inf --> 0.762207).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.917463 \tValidation Loss: 0.873379\n",
      "Epoch: 3 \tTraining Loss: 0.891408 \tValidation Loss: 0.757641\n",
      "Validation loss decreased (0.762207 --> 0.757641).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.874580 \tValidation Loss: 0.710157\n",
      "Validation loss decreased (0.757641 --> 0.710157).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.836264 \tValidation Loss: 0.776888\n",
      "Epoch: 6 \tTraining Loss: 0.876131 \tValidation Loss: 0.793070\n",
      "Epoch: 7 \tTraining Loss: 0.822339 \tValidation Loss: 0.757774\n",
      "Epoch: 8 \tTraining Loss: 0.795826 \tValidation Loss: 0.810662\n",
      "Epoch: 9 \tTraining Loss: 0.781622 \tValidation Loss: 0.745562\n",
      "Epoch: 10 \tTraining Loss: 0.795154 \tValidation Loss: 0.758364\n",
      "Epoch: 11 \tTraining Loss: 0.792295 \tValidation Loss: 0.822828\n",
      "Epoch: 12 \tTraining Loss: 0.813188 \tValidation Loss: 0.761408\n",
      "Epoch: 13 \tTraining Loss: 0.811930 \tValidation Loss: 0.757285\n",
      "Epoch: 14 \tTraining Loss: 0.784180 \tValidation Loss: 0.644256\n",
      "Validation loss decreased (0.710157 --> 0.644256).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.794671 \tValidation Loss: 0.663204\n",
      "Epoch: 16 \tTraining Loss: 0.796618 \tValidation Loss: 0.794821\n",
      "Epoch: 17 \tTraining Loss: 0.799895 \tValidation Loss: 0.898869\n",
      "Epoch: 18 \tTraining Loss: 0.807199 \tValidation Loss: 0.819869\n",
      "Epoch: 19 \tTraining Loss: 0.759886 \tValidation Loss: 0.622802\n",
      "Validation loss decreased (0.644256 --> 0.622802).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.759510 \tValidation Loss: 0.736362\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_transfer_3 =train(20, loaders_transfer, model_transfer_3, optimizer_transfer_3, criterion_transfer_3, train_on_gpu, 'model_transfer_3.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "model_transfer_3.load_state_dict(torch.load('model_transfer_3.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.937307\n",
      "\n",
      "\n",
      "Test Accuracy: 54% (327/600)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, train_on_gpu):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        # move to GPU\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "    \n",
    "# call test function \n",
    "test(loaders_transfer, model_transfer_3, criterion_transfer_3, train_on_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envTest] *",
   "language": "python",
   "name": "conda-env-envTest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
